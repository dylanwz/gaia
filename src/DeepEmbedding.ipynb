{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `dataAnalysis/main.ipynb` for the preceeding and successive stages.\n",
    "\n",
    "This file implements an unsupervised deep embedding process for clustering analysis.\n",
    "<br>\n",
    "> A. Constructing an unsupervised deep learning model (e.g. autoencoders).\n",
    "<br>\n",
    "> B. Training the deep embedding model to minimise a reconstruction error.\n",
    "<br>\n",
    "> C. Embedding generation. \n",
    "<br>\n",
    "> D. Clustering in the embedding space.\n",
    "\n",
    "\n",
    "Pre-requisite knowledge: simple feedforward perceptrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NN libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A. Constructing An Autoencoder.__\n",
    "<br>\n",
    "Autoencodoers consist of two parts: an `encoder` and a `decoder`.\n",
    "<br>\n",
    "The autoencoder can be expressed as\n",
    "\n",
    "> `L(x,g(f(x))`,\n",
    "\n",
    "for some input space `x` and non-linear encoder and decoder functions `f,` `g`. Note the lower-dimensional latent space is often denoted `f(x) = h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataAnalysis import DataAnalysis\n",
    "\n",
    "class undercompleteAE():\n",
    "    def __init__(self):\n",
    "        data = DataAnalysis(\"data/star_data.fits\")\n",
    "        # Take the parameters from dataAnalysis, i.e. numRow amount of numCol-dimensional column vector. This is the input space.\n",
    "        inputLayer = keras.Input(shape=(data.numRow(),data.numCol(),1), name=\"rawInput\")\n",
    "        encoderInputLayer = keras.layers.Flatten(name=\"encoderStart\")(inputLayer)\n",
    "        # Compress this input space into a lower-dimensional latent space, i.e. h.\n",
    "        encoderOutputLayer = keras.layers.Dense((data.numRow()*data.numCol()/8), activation=\"relu\", name=\"bottleNeck\")(encoderInputLayer)\n",
    "\n",
    "        # Similarly for the decoder, we take the latent space h and (try to) reconstruct to the input space x\n",
    "        decoderInputLayer = keras.layers.Dense(data.numRow()*data.numCol(), activation=\"relu\",name=\"decoderStart\")(encoderOutputLayer)\n",
    "        # Hence giving L(x, g(f(x)))\n",
    "        decoderOutputLayer = keras.layers.Reshape((data.numRow(),data.numCol(),1), name=\"reconstruction\")(decoderInputLayer)\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.autoencoder = keras.Model(inputLayer, decoderOutputLayer, name=\"autoencoder\")\n",
    "\n",
    "    def summary(self):\n",
    "        self.autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'log(cm.s**-2)' did not parse as fits unit: 'log' is not a recognized function If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: ''dex'' did not parse as fits unit: At col 0, Unit ''dex'' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rawInput (InputLayer)       [(None, 30, 23, 1)]       0         \n",
      "                                                                 \n",
      " encoderStart (Flatten)      (None, 690)               0         \n",
      "                                                                 \n",
      " bottleNeck (Dense)          (None, 86)                59426     \n",
      "                                                                 \n",
      " decoderStart (Dense)        (None, 690)               60030     \n",
      "                                                                 \n",
      " reconstruction (Reshape)    (None, 30, 23, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119456 (466.62 KB)\n",
      "Trainable params: 119456 (466.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "e = undercompleteAE()\n",
    "e.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
